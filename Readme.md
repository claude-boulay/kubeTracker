# Projet Kubernetes - Application Fleetman

D√©ploiement d'une application distribu√©e de suivi de flotte de v√©hicules sur Kubernetes.

## üìã Table des Mati√®res

- [Vue d'ensemble](#vue-densemble)
- [Pr√©requis](#pr√©requis)
- [Architecture](#architecture)
- [Installation rapide](#installation-rapide)
- [D√©ploiement d√©taill√©](#d√©ploiement-d√©taill√©)
- [V√©rification](#v√©rification)
- [Acc√®s √† l'application](#acc√®s-√†-lapplication)
- [Maintenance](#maintenance)
- [D√©pannage](#d√©pannage)

---

## üéØ Vue d'ensemble

Cette application permet de suivre en temps r√©el une flotte de v√©hicules effectuant des livraisons. Elle est compos√©e de 6 microservices d√©ploy√©s sur Kubernetes :

- **fleetman-position-simulator** : G√©n√®re des positions fictives de v√©hicules
- **fleetman-queue** : Queue ActiveMQ pour le messaging
- **fleetman-position-tracker** : API RESTful pour g√©rer les positions
- **fleetman-mongodb** : Base de donn√©es pour la persistance
- **fleetman-api-gateway** : Point d'entr√©e pour l'application web
- **fleetman-web-app** : Interface web pour visualiser les v√©hicules

---

## üì¶ Pr√©requis

### Cluster Kubernetes

- **Kubernetes** : v1.24 ou sup√©rieur
- **N≈ìuds** : 1 master + 2 workers (minimum)
- **kubectl** : Install√© et configur√©

### Ressources minimales

- **CPU total** : 4 cores
- **RAM totale** : 8 GB
- **Stockage** : 20 GB disponibles

### V√©rification

```bash
# V√©rifier la version de Kubernetes
kubectl version --short

# V√©rifier les n≈ìuds
kubectl get nodes

# V√©rifier les ressources disponibles
kubectl top nodes
```

---

## üèóÔ∏è Architecture

### Composants d√©ploy√©s

| Service | Type | Replicas | Port | Acc√®s |
|---------|------|----------|------|-------|
| fleetman-queue | ClusterIP + NodePort | 1 | 61616, 8161 | Interne + Admin (30161) |
| fleetman-position-simulator | ClusterIP | 1 | 8080 | Interne |
| fleetman-position-tracker | ClusterIP | 2 | 8080 | Interne |
| fleetman-mongodb | ClusterIP | 1 | 27017 | Interne |
| fleetman-api-gateway | ClusterIP | 2 | 8080 | Interne |
| fleetman-web-app | NodePort | 2 | 80 | Externe (30080) |

### Flux de donn√©es

```
Position Simulator ‚Üí ActiveMQ Queue ‚Üí Position Tracker ‚Üí MongoDB
                                              ‚Üì
                            API Gateway ‚Üê MongoDB
                                  ‚Üì
                              Web App
```

### Haute disponibilit√©

- **Replicas multiples** : Les services critiques (web-app, api-gateway, position-tracker) ont 2 replicas
- **Anti-affinity** : Les pods sont distribu√©s sur diff√©rents n≈ìuds workers
- **Probes** : Liveness et Readiness probes configur√©es pour tous les services

---

## ‚ö° Installation Rapide

### Option 1 : D√©ploiement complet

```bash
# 1. Cloner ou extraire le projet
cd ProjetFinal

# 2. Cr√©er le r√©pertoire de stockage sur CHAQUE worker
# Sur worker-1 et worker-2 :
sudo mkdir -p /mnt/data/mongodb
sudo chmod 777 /mnt/data/mongodb

# 3. D√©ployer tous les manifestes
kubectl apply -f k8s-manifests/

# 4. Attendre que tous les pods soient pr√™ts
kubectl wait --for=condition=ready pod --all -n fleetman --timeout=5m

# 5. Acc√©der √† l'application
kubectl get nodes -o wide
# Ouvrir http://<WORKER_IP>:30080 dans le navigateur
```

### Option 2 : D√©ploiement pas √† pas

```bash
# D√©ployer dans l'ordre
kubectl apply -f k8s-manifests/00-namespace.yaml
kubectl apply -f k8s-manifests/01-mongodb-storage.yaml
kubectl apply -f k8s-manifests/02-mongodb-deployment.yaml
kubectl apply -f k8s-manifests/02-mongodb-service.yaml
kubectl apply -f k8s-manifests/03-queue-deployment.yaml
kubectl apply -f k8s-manifests/03-queue-service.yaml
kubectl apply -f k8s-manifests/03-queue-admin-service.yaml
kubectl apply -f k8s-manifests/04-position-simulator-deployment.yaml
kubectl apply -f k8s-manifests/04-position-simulator-service.yaml
kubectl apply -f k8s-manifests/05-position-tracker-deployment.yaml
kubectl apply -f k8s-manifests/05-position-tracker-service.yaml
kubectl apply -f k8s-manifests/06-api-gateway-deployment.yaml
kubectl apply -f k8s-manifests/06-api-gateway-service.yaml
kubectl apply -f k8s-manifests/07-web-app-deployment.yaml
kubectl apply -f k8s-manifests/07-web-app-service.yaml
```

---

## üìñ D√©ploiement D√©taill√©

### √âtape 1 : Pr√©paration du stockage

Le service MongoDB n√©cessite un stockage persistant. Sur **chaque n≈ìud worker**, cr√©er le r√©pertoire :

```bash
# Se connecter sur worker-1
ssh user@worker-1
sudo mkdir -p /mnt/data/mongodb
sudo chmod 777 /mnt/data/mongodb
exit

# Se connecter sur worker-2
ssh user@worker-2
sudo mkdir -p /mnt/data/mongodb
sudo chmod 777 /mnt/data/mongodb
exit
```

### √âtape 2 : Cr√©er le namespace

```bash
kubectl apply -f k8s-manifests/00-namespace.yaml

# V√©rifier
kubectl get namespaces
```

### √âtape 3 : D√©ployer le stockage MongoDB

```bash
kubectl apply -f k8s-manifests/01-mongodb-storage.yaml

# V√©rifier
kubectl get pv
kubectl get pvc -n fleetman
```

Le PVC doit √™tre en √©tat `Bound`.

### √âtape 4 : D√©ployer MongoDB

```bash
kubectl apply -f k8s-manifests/02-mongodb-deployment.yaml
kubectl apply -f k8s-manifests/02-mongodb-service.yaml

# V√©rifier
kubectl get pods -n fleetman -l app=fleetman-mongodb
kubectl get svc -n fleetman fleetman-mongodb
```

Attendre que le pod MongoDB soit `Running` avant de continuer.

### √âtape 5 : D√©ployer ActiveMQ Queue

```bash
kubectl apply -f k8s-manifests/03-queue-deployment.yaml
kubectl apply -f k8s-manifests/03-queue-service.yaml
kubectl apply -f k8s-manifests/03-queue-admin-service.yaml

# V√©rifier
kubectl get pods -n fleetman -l app=fleetman-queue
kubectl get svc -n fleetman | grep queue
```

### √âtape 6 : D√©ployer Position Simulator

```bash
kubectl apply -f k8s-manifests/04-position-simulator-deployment.yaml
kubectl apply -f k8s-manifests/04-position-simulator-service.yaml

# V√©rifier
kubectl get pods -n fleetman -l app=fleetman-position-simulator
```

### √âtape 7 : D√©ployer Position Tracker

```bash
kubectl apply -f k8s-manifests/05-position-tracker-deployment.yaml
kubectl apply -f k8s-manifests/05-position-tracker-service.yaml

# V√©rifier
kubectl get pods -n fleetman -l app=fleetman-position-tracker
```

Ce service a 2 replicas pour la haute disponibilit√©.

### √âtape 8 : D√©ployer API Gateway

```bash
kubectl apply -f k8s-manifests/06-api-gateway-deployment.yaml
kubectl apply -f k8s-manifests/06-api-gateway-service.yaml

# V√©rifier
kubectl get pods -n fleetman -l app=fleetman-api-gateway
```

### √âtape 9 : D√©ployer Web App

```bash
kubectl apply -f k8s-manifests/07-web-app-deployment.yaml
kubectl apply -f k8s-manifests/07-web-app-service.yaml

# V√©rifier
kubectl get pods -n fleetman -l app=fleetman-web-app
kubectl get svc -n fleetman fleetman-web-app
```

---

## ‚úÖ V√©rification

### V√©rifier tous les pods

```bash
kubectl get pods -n fleetman

# Tous les pods doivent √™tre en √©tat Running
# R√©sultat attendu :
# NAME                                          READY   STATUS    RESTARTS   AGE
# fleetman-api-gateway-xxxxx                    1/1     Running   0          2m
# fleetman-api-gateway-yyyyy                    1/1     Running   0          2m
# fleetman-mongodb-xxxxx                        1/1     Running   0          5m
# fleetman-position-simulator-xxxxx             1/1     Running   0          3m
# fleetman-position-tracker-xxxxx               1/1     Running   0          3m
# fleetman-position-tracker-yyyyy               1/1     Running   0          3m
# fleetman-queue-xxxxx                          1/1     Running   0          4m
# fleetman-web-app-xxxxx                        1/1     Running   0          1m
# fleetman-web-app-yyyyy                        1/1     Running   0          1m
```

### V√©rifier tous les services

```bash
kubectl get svc -n fleetman

# R√©sultat attendu :
# NAME                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)
# fleetman-api-gateway        ClusterIP   10.96.xxx.xxx    <none>        8080/TCP
# fleetman-mongodb            ClusterIP   10.96.xxx.xxx    <none>        27017/TCP
# fleetman-position-simulator ClusterIP   10.96.xxx.xxx    <none>        8080/TCP
# fleetman-position-tracker   ClusterIP   10.96.xxx.xxx    <none>        8080/TCP
# fleetman-queue              ClusterIP   10.96.xxx.xxx    <none>        61616/TCP,8161/TCP
# fleetman-queue-admin        NodePort    10.96.xxx.xxx    <none>        8161:30161/TCP
# fleetman-web-app            NodePort    10.96.xxx.xxx    <none>        80:30080/TCP
```

### V√©rifier la distribution des pods

```bash
kubectl get pods -n fleetman -o wide

# Les pods avec replicas multiples doivent √™tre sur des n≈ìuds diff√©rents
```

### V√©rifier les logs

```bash
# Logs de la queue
kubectl logs -n fleetman -l app=fleetman-queue

# Logs du position tracker
kubectl logs -n fleetman -l app=fleetman-position-tracker

# Logs de l'API gateway
kubectl logs -n fleetman -l app=fleetman-api-gateway
```

Si des erreurs apparaissent, consultez la section [D√©pannage](#d√©pannage).

---

## üåê Acc√®s √† l'Application

### Application Web Fleetman

1. R√©cup√©rer l'IP d'un n≈ìud worker :

```bash
kubectl get nodes -o wide
# Noter la INTERNAL-IP ou EXTERNAL-IP d'un worker
```

2. Ouvrir dans un navigateur :

```
http://<WORKER_IP>:30080
```

Vous devriez voir :
- Une carte avec des √©pingles repr√©sentant les v√©hicules
- Une liste de v√©hicules sur la droite
- Les positions se mettent √† jour automatiquement

### Interface Admin ActiveMQ (optionnel)

Pour acc√©der √† l'interface d'administration ActiveMQ :

```
http://<WORKER_IP>:30161
```

Identifiants par d√©faut :
- **Username** : admin
- **Password** : admin

### Acc√®s depuis kubectl port-forward (alternative)

Si les NodePort ne fonctionnent pas, utiliser port-forward :

```bash
# Web App
kubectl port-forward -n fleetman svc/fleetman-web-app 8080:80

# Acc√©der √† http://localhost:8080
```

---

## üîß Maintenance

### Scaler les d√©ploiements

```bash
# Augmenter le nombre de replicas du web-app
kubectl scale deployment fleetman-web-app -n fleetman --replicas=3

# V√©rifier
kubectl get pods -n fleetman -l app=fleetman-web-app
```

### Red√©marrer un service

```bash
# Red√©marrer la queue (utile si les positions ne s'affichent pas)
kubectl rollout restart deployment fleetman-queue -n fleetman

# Suivre le red√©marrage
kubectl rollout status deployment fleetman-queue -n fleetman
```

### Mettre √† jour une image

```bash
# Exemple : mettre √† jour le web-app
kubectl set image deployment/fleetman-web-app \
  web-app=supinfo4kube/web-app:1.0.1 \
  -n fleetman

# Suivre la mise √† jour
kubectl rollout status deployment fleetman-web-app -n fleetman
```

### Voir les √©v√©nements

```bash
# Tous les √©v√©nements du namespace
kubectl get events -n fleetman --sort-by='.lastTimestamp'

# √âv√©nements d'un pod sp√©cifique
kubectl describe pod <nom-du-pod> -n fleetman
```

---

## üêõ D√©pannage

### Probl√®me : Les pods restent en Pending

**Causes possibles :**
- Ressources insuffisantes sur les n≈ìuds
- PersistentVolume non disponible

**Solutions :**

```bash
# V√©rifier les ressources
kubectl describe pod <nom-du-pod> -n fleetman
kubectl top nodes

# V√©rifier le PV
kubectl get pv
kubectl describe pv mongodb-pv
```

### Probl√®me : MongoDB ne d√©marre pas

**Solution :**

```bash
# V√©rifier que le r√©pertoire existe sur les workers
kubectl get pods -n fleetman -l app=fleetman-mongodb -o wide
# Noter sur quel n≈ìud le pod est planifi√©

# Se connecter au n≈ìud et v√©rifier
ssh user@<node>
ls -la /mnt/data/mongodb
sudo chown -R 999:999 /mnt/data/mongodb  # UID de MongoDB
```

### Probl√®me : Les positions ne s'affichent pas

**Solutions :**

```bash
# 1. Red√©marrer la queue
kubectl rollout restart deployment fleetman-queue -n fleetman

# 2. V√©rifier les logs
kubectl logs -n fleetman -l app=fleetman-position-simulator
kubectl logs -n fleetman -l app=fleetman-position-tracker

# 3. V√©rifier la connectivit√© entre les services
kubectl run -it --rm debug --image=busybox --restart=Never -n fleetman -- sh
# Dans le pod :
wget -O- http://fleetman-queue:61616
wget -O- http://fleetman-api-gateway:8080
```

### Probl√®me : Impossible d'acc√©der au web-app via NodePort

**Solutions :**

```bash
# V√©rifier le service
kubectl get svc -n fleetman fleetman-web-app

# V√©rifier les r√®gles de firewall
# Sur chaque worker :
sudo ufw status
sudo ufw allow 30080/tcp
sudo ufw allow 30161/tcp

# V√©rifier que kube-proxy fonctionne
kubectl get pods -n kube-system | grep kube-proxy
```

### Probl√®me : L'application ne r√©siste pas √† la panne d'un worker

**V√©rifications :**

```bash
# V√©rifier que les pods ont plusieurs replicas
kubectl get deployments -n fleetman

# V√©rifier la distribution des pods
kubectl get pods -n fleetman -o wide

# V√©rifier l'anti-affinity
kubectl describe pod <nom-du-pod> -n fleetman | grep -A 10 "Affinity"
```

### Commandes de diagnostic

```bash
# Obtenir des informations compl√®tes sur un pod
kubectl describe pod <nom-du-pod> -n fleetman

# Acc√©der √† un pod pour d√©boguer
kubectl exec -it <nom-du-pod> -n fleetman -- /bin/sh

# Voir l'utilisation des ressources
kubectl top pods -n fleetman

# Dump de la configuration
kubectl get all -n fleetman -o yaml > fleetman-dump.yaml
```

---

## üßπ Nettoyage

### Supprimer l'application

```bash
# Supprimer tous les ressources
kubectl delete -f k8s-manifests/

# Ou supprimer le namespace (supprime tout)
kubectl delete namespace fleetman

# Supprimer le PersistentVolume
kubectl delete pv mongodb-pv
```

### Nettoyer les donn√©es sur les workers

```bash
# Sur chaque worker
ssh user@worker
sudo rm -rf /mnt/data/mongodb
```

---

## üìä Test de R√©silience

### Test de d√©faillance d'un n≈ìud

```bash
# 1. Noter la distribution initiale des pods
kubectl get pods -n fleetman -o wide

# 2. Simuler une panne en stoppant kubelet sur worker-1
# Sur worker-1 :
sudo systemctl stop kubelet

# 3. Observer la migration des pods (attendre ~5 minutes)
kubectl get pods -n fleetman -o wide --watch

# 4. V√©rifier que l'application reste accessible
curl http://<WORKER_2_IP>:30080

# 5. Red√©marrer le worker
# Sur worker-1 :
sudo systemctl start kubelet

# 6. V√©rifier que tout revient √† la normale
kubectl get pods -n fleetman -o wide
```

---

## üìö Documentation Compl√©mentaire

- **Documentation du cluster** : Voir `documentation-cluster-kubernetes.md` pour la mise en place du cluster
- **Sujet du projet** : Voir `sujet.md` pour les d√©tails du projet
- **Manifestes Kubernetes** : Tous les fichiers YAML sont dans `k8s-manifests/`

---

## üéì Points d'√âvaluation

### Checklist de validation (40 points)

- [x] **D√©ploiement position-simulator** (2 pts) - Fichiers `04-position-simulator-deployment.yaml`, `04-position-simulator-service.yaml`
- [x] **D√©ploiement queue** (2 pts) - Fichiers `03-queue-deployment.yaml`, `03-queue-service.yaml`, `03-queue-admin-service.yaml`
- [x] **D√©ploiement position-tracker** (2 pts) - Fichiers `05-position-tracker-deployment.yaml`, `05-position-tracker-service.yaml`
- [x] **D√©ploiement api-gateway** (2 pts) - Fichiers `06-api-gateway-deployment.yaml`, `06-api-gateway-service.yaml`
- [x] **D√©ploiement web-app** (2 pts) - Fichiers `07-web-app-deployment.yaml`, `07-web-app-service.yaml`
- [x] **MongoDB persist√©** (7 pts) - Fichiers `01-mongodb-storage.yaml`, `02-mongodb-deployment.yaml`, `02-mongodb-service.yaml`
- [x] **Isolation appropri√©e** (3 pts) - Namespace d√©di√© + services ClusterIP/NodePort appropri√©s
- [x] **Documentation cluster** (13 pts) - Fichier `documentation-cluster-kubernetes.md`
- [x] **Instructions claires** (3 pts) - Ce fichier README.md
- [x] **R√©silience worker** (4 pts) - Replicas + Anti-affinity configur√©s

**Total : 40 points**

---

## üìù Notes

- Cette application a √©t√© d√©ploy√©e et test√©e sur un cluster Kubernetes 1.28
- Les manifestes sont num√©rot√©s pour faciliter le d√©ploiement dans l'ordre
- Les services utilisent `production-microservice` comme profil Spring
- L'image du web-app est `1.0.0` (et non `1.0.0-dockercompose`)
- La haute disponibilit√© est assur√©e par des replicas multiples et l'anti-affinity

---

## üë• Auteurs

Projet r√©alis√© dans le cadre du cours Kubernetes - SupInfo 4√®me ann√©e

---

## üìû Support

En cas de probl√®me :
1. Consulter la section [D√©pannage](#d√©pannage)
2. V√©rifier les logs : `kubectl logs -n fleetman <nom-du-pod>`
3. Consulter la documentation compl√®te : `documentation-cluster-kubernetes.md`

---

**Bon d√©ploiement ! üöÄ**

